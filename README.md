# Legal RAG - Há»‡ Thá»‘ng Trá»£ LÃ½ PhÃ¡p LÃ½ ThÃ´ng Minh

Há»‡ thá»‘ng RAG (Retrieval-Augmented Generation) sá»­ dá»¥ng AI Ä‘á»ƒ tráº£ lá»i cÃ¡c cÃ¢u há»i vá» phÃ¡p luáº­t Viá»‡t Nam má»™t cÃ¡ch chÃ­nh xÃ¡c vÃ  cÃ³ nguá»“n gá»‘c.

## ğŸ“‹ Má»¥c Lá»¥c

- [Giá»›i Thiá»‡u](#-giá»›i-thiá»‡u)
- [Quick Start vá»›i Docker](#-quick-start-vá»›i-docker)
- [Kiáº¿n TrÃºc Há»‡ Thá»‘ng](#ï¸-kiáº¿n-trÃºc-há»‡-thá»‘ng)
- [CÃ´ng Nghá»‡ Sá»­ Dá»¥ng](#ï¸-cÃ´ng-nghá»‡-sá»­-dá»¥ng)
- [CÃ¡ch Hoáº¡t Äá»™ng](#ï¸-cÃ¡ch-hoáº¡t-Ä‘á»™ng)
- [CÃ i Äáº·t](#-cÃ i-Ä‘áº·t)
- [Sá»­ Dá»¥ng](#-sá»­-dá»¥ng)
- [Cáº¥u TrÃºc Project](#-cáº¥u-trÃºc-project)
- [API Documentation](#-api-documentation)
- [Configuration](#-configuration)

---

## ğŸ¯ Giá»›i Thiá»‡u

### Váº¥n Äá» Cáº§n Giáº£i Quyáº¿t

Viá»‡c tra cá»©u vÃ  hiá»ƒu cÃ¡c quy Ä‘á»‹nh phÃ¡p luáº­t Viá»‡t Nam thÆ°á»ng gáº·p nhiá»u khÃ³ khÄƒn:
- **Khá»‘i lÆ°á»£ng lá»›n**: HÃ ng nghÃ¬n Ä‘iá»u luáº­t, nghá»‹ Ä‘á»‹nh, thÃ´ng tÆ°
- **NgÃ´n ngá»¯ phá»©c táº¡p**: Thuáº­t ngá»¯ phÃ¡p lÃ½ khÃ³ hiá»ƒu
- **TÃ¬m kiáº¿m khÃ³ khÄƒn**: KhÃ´ng biáº¿t tÃ¬m á»Ÿ Ä‘Ã¢u, Ä‘iá»u nÃ o
- **ThÃ´ng tin lá»—i thá»i**: Luáº­t thay Ä‘á»•i liÃªn tá»¥c

### Giáº£i PhÃ¡p

**Legal RAG** lÃ  há»‡ thá»‘ng AI káº¿t há»£p:
1. **Retrieval**: TÃ¬m kiáº¿m thÃ´ng minh trong cÆ¡ sá»Ÿ dá»¯ liá»‡u phÃ¡p luáº­t
2. **Generation**: Táº¡o cÃ¢u tráº£ lá»i dá»… hiá»ƒu báº±ng AI
3. **Agentic**: Tá»± Ä‘á»™ng quyáº¿t Ä‘á»‹nh cÃ¡ch tÃ¬m kiáº¿m tá»‘t nháº¥t
4. **Web Search**: TÃ¬m kiáº¿m thÃ´ng tin má»›i nháº¥t trÃªn internet (self-hosted)

**Káº¿t quáº£**: Tráº£ lá»i chÃ­nh xÃ¡c, cÃ³ trÃ­ch dáº«n Ä‘iá»u luáº­t cá»¥ thá»ƒ, dá»… hiá»ƒu.

---

## ğŸ³ Quick Start vá»›i Docker

**CÃ¡ch nhanh nháº¥t Ä‘á»ƒ cháº¡y toÃ n bá»™ há»‡ thá»‘ng!**

### Prerequisites
- Docker & Docker Compose
- (Optional) NVIDIA GPU + nvidia-docker cho Ollama

### BÆ°á»›c 1: Clone vÃ  Start

```bash
# Clone repository
git clone <repository-url>
cd Legal-RAG

# Start táº¥t cáº£ services
docker-compose up -d

# Xem logs
docker-compose logs -f
```

### BÆ°á»›c 2: Initialize

```bash
# Pull Ollama model vÃ  ingest data
./docker-init.sh
```

### BÆ°á»›c 3: Test

```bash
curl -X POST http://localhost:8080/api/legal-query \
  -H "Content-Type: application/json" \
  -d '{"question": "Thá»i gian thá»­ viá»‡c tá»‘i Ä‘a bao nhiÃªu ngÃ y?"}'
```

### Services Running

- **Frontend UI**: http://localhost:5173
- **Backend API**: http://localhost:8080
- **AI Engine**: http://localhost:8000
- **Qdrant**: http://localhost:6333
- **Ollama**: http://localhost:11434
- **SearXNG**: http://localhost:8888

### Useful Commands

```bash
# Stop services
docker-compose down

# Rebuild images
docker-compose build

# View logs
docker-compose logs -f [service-name]

# Restart a service
docker-compose restart [service-name]

# Remove all data (volumes)
docker-compose down -v
```

### GPU Support (Optional)

Náº¿u báº¡n cÃ³ NVIDIA GPU, uncomment pháº§n GPU trong `docker-compose.yml`:

```yaml
# ollama service
deploy:
  resources:
    reservations:
      devices:
        - driver: nvidia
          count: 1
          capabilities: [gpu]
```

---

## ğŸ—ï¸ Kiáº¿n TrÃºc Há»‡ Thá»‘ng

### Tá»•ng Quan

```mermaid
graph TB
    Frontend[React Frontend<br/>Port 5173] -->|HTTP POST| GoAPI[Go Backend API<br/>Port 8080]
    GoAPI -->|HTTP POST| PyEngine[Python AI Engine<br/>Port 8000]
    
    PyEngine --> Agent[Agentic RAG<br/>LangGraph]
    
    Agent -->|1. Search| Qdrant[(Qdrant<br/>Vector DB)]
    Agent -->|2. Generate| Ollama[Ollama LLM<br/>qwen2.5:7b]
    Agent -->|3. Web Search| SearXNG[SearXNG<br/>Self-hosted Search]
    
    Qdrant -->|Results| Agent
    Ollama -->|Answer| Agent
    SearXNG -->|Web Results| Agent
    
    Agent -->|Response| PyEngine
    PyEngine -->|JSON| GoAPI
    GoAPI -->|JSON| Frontend
    
    style Frontend fill:#e1f5fe
    style GoAPI fill:#fff3e0
    style PyEngine fill:#f3e5f5
    style Agent fill:#e8f5e9
    style Qdrant fill:#fce4ec
    style Ollama fill:#fff9c4
    style SearXNG fill:#e0f2f1
```

### CÃ¡c ThÃ nh Pháº§n

#### 0. **React Frontend** (Port 5173)
- **Vai trÃ²**: Giao diá»‡n ngÆ°á»i dÃ¹ng tÆ°Æ¡ng tÃ¡c
- **CÃ´ng nghá»‡**: React + TypeScript + Vite + TailwindCSS
- **Chá»©c nÄƒng**:
  - Gá»­i cÃ¢u há»i vÃ  hiá»ƒn thá»‹ cÃ¢u tráº£ lá»i
  - Trá»±c quan hÃ³a quÃ¡ trÃ¬nh suy luáº­n (Reasoning)
  - Hiá»ƒn thá»‹ nguá»“n trÃ­ch dáº«n phÃ¡p lÃ½ vÃ  káº¿t quáº£ Web
  - TÃ¹y chá»‰nh cáº¥u hÃ¬nh AI (Max iterations, TopK)

#### 1. **Go Backend API** (Port 8080)
- **Vai trÃ²**: Gateway giá»¯a client vÃ  AI engine
- **CÃ´ng nghá»‡**: Go + Gin framework
- **Chá»©c nÄƒng**:
  - Nháº­n request tá»« client
  - Validate vÃ  forward Ä‘áº¿n Python
  - Tráº£ response vá» client
  - Health check

#### 2. **Python AI Engine** (Port 8000)
- **Vai trÃ²**: Xá»­ lÃ½ logic AI vÃ  RAG
- **CÃ´ng nghá»‡**: Python + FastAPI
- **Chá»©c nÄƒng**:
  - Expose HTTP API
  - Cháº¡y Agentic RAG workflow
  - Quáº£n lÃ½ káº¿t ná»‘i vá»›i Qdrant, Ollama, SearXNG

#### 3. **Agentic RAG** (LangGraph)
- **Vai trÃ²**: "Bá»™ nÃ£o" cá»§a há»‡ thá»‘ng
- **CÃ´ng nghá»‡**: LangGraph + LangChain
- **Chá»©c nÄƒng**:
  - Quyáº¿t Ä‘á»‹nh chiáº¿n lÆ°á»£c tÃ¬m kiáº¿m
  - Tinh chá»‰nh query náº¿u cáº§n
  - Káº¿t há»£p nhiá»u nguá»“n thÃ´ng tin
  - Táº¡o cÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng

#### 4. **Qdrant Vector Database**
- **Vai trÃ²**: LÆ°u trá»¯ vÃ  tÃ¬m kiáº¿m vÄƒn báº£n phÃ¡p luáº­t
- **CÃ´ng nghá»‡**: Qdrant (vector similarity search)
- **Dá»¯ liá»‡u**: Embedding cá»§a cÃ¡c Ä‘iá»u luáº­t Viá»‡t Nam

#### 5. **Ollama LLM**
- **Vai trÃ²**: Táº¡o cÃ¢u tráº£ lá»i tá»± nhiÃªn
- **Model**: qwen2.5:7b (Vietnamese-capable)
- **Chá»©c nÄƒng**:
  - PhÃ¢n tÃ­ch cÃ¢u há»i
  - Quyáº¿t Ä‘á»‹nh hÃ nh Ä‘á»™ng
  - Táº¡o cÃ¢u tráº£ lá»i tá»« káº¿t quáº£ tÃ¬m kiáº¿m

#### 6. **SearXNG** (Self-hosted Search Engine)
- **Vai trÃ²**: TÃ¬m kiáº¿m thÃ´ng tin má»›i nháº¥t trÃªn internet
- **CÃ´ng nghá»‡**: SearXNG metasearch engine
- **Æ¯u Ä‘iá»ƒm**:
  - ğŸ†“ HoÃ n toÃ n miá»…n phÃ­, khÃ´ng cáº§n API key
  - ğŸ”’ RiÃªng tÆ°, táº¥t cáº£ search cháº¡y local
  - âš¡ KhÃ´ng giá»›i háº¡n sá»‘ lÆ°á»£ng search
  - ğŸ‡»ğŸ‡³ Há»— trá»£ tiáº¿ng Viá»‡t tá»‘t
  - ğŸ” Tá»•ng há»£p tá»« nhiá»u search engines (Google, Bing, DuckDuckGo, Brave...)

---

## ğŸ› ï¸ CÃ´ng Nghá»‡ Sá»­ Dá»¥ng

### Frontend
- **React 18+**: UI Library
- **TypeScript**: Static typing
- **Vite**: Build tool & dev server
- **TailwindCSS v4**: Styling
- **Framer Motion**: Animations
- **Lucide React**: Icons
- **Axios**: HTTP Client

### Backend
- **Go 1.21+**: Backend API gateway
  - `gin-gonic/gin`: Web framework
- **Python 3.8+**: AI Engine
  - `fastapi`: HTTP API framework
  - `uvicorn`: ASGI server

### AI/ML Stack
- **LangGraph**: Agentic workflow orchestration
- **LangChain**: LLM application framework
- **Sentence Transformers**: Vietnamese text embedding
- **Qdrant**: Vector database
- **Ollama**: Local LLM inference

### Search
- **SearXNG**: Self-hosted metasearch engine
  - Privacy-focused
  - No API costs
  - Aggregates results from multiple engines

---

## âš™ï¸ CÃ¡ch Hoáº¡t Äá»™ng

### Workflow Chi Tiáº¿t

```mermaid
stateDiagram-v2
    [*] --> ReceiveQuestion
    ReceiveQuestion --> DecideAction: PhÃ¢n tÃ­ch cÃ¢u há»i
    
    DecideAction --> RefineQuery: Cáº§n cáº£i thiá»‡n query
    DecideAction --> SearchInternal: TÃ¬m trong DB
    DecideAction --> SearchWeb: TÃ¬m trÃªn web
    DecideAction --> GenerateAnswer: Äá»§ thÃ´ng tin
    
    RefineQuery --> SearchInternal: Query Ä‘Ã£ tá»‘t hÆ¡n
    
    SearchInternal --> DecideAction: Kiá»ƒm tra káº¿t quáº£
    SearchWeb --> DecideAction: Kiá»ƒm tra káº¿t quáº£
    
    GenerateAnswer --> [*]: Tráº£ vá» cÃ¢u tráº£ lá»i
```

### CÃ¡c BÆ°á»›c Xá»­ LÃ½

1. **Nháº­n CÃ¢u Há»i**
   ```
   Client â†’ Go API â†’ Python API â†’ Agentic RAG
   ```

2. **Decide Action** (Quyáº¿t Ä‘á»‹nh hÃ nh Ä‘á»™ng)
   - LLM phÃ¢n tÃ­ch cÃ¢u há»i
   - Quyáº¿t Ä‘á»‹nh: search, refine, hoáº·c answer
   - VÃ­ dá»¥: "Thá»i gian thá»­ viá»‡c tá»‘i Ä‘a?" â†’ search

3. **Search** (TÃ¬m kiáº¿m)
   - **Internal Search**: TÃ¬m trong Qdrant DB
     - Embedding cÃ¢u há»i
     - Similarity search
     - Láº¥y top-k káº¿t quáº£
   - **Web Search**: TÃ¬m trÃªn internet qua SearXNG
     - Tá»± Ä‘á»™ng trigger khi cáº§n thÃ´ng tin má»›i nháº¥t
     - Tá»•ng há»£p tá»« nhiá»u search engines
     - Há»— trá»£ tiáº¿ng Viá»‡t

4. **Refine Query** (Tinh chá»‰nh - náº¿u cáº§n)
   - LLM phÃ¢n tÃ­ch káº¿t quáº£ hiá»‡n táº¡i
   - Táº¡o query tá»‘t hÆ¡n
   - VÃ­ dá»¥: "thá»­ viá»‡c" â†’ "thá»i gian thá»­ viá»‡c Bá»™ luáº­t Lao Ä‘á»™ng"

5. **Generate Answer** (Táº¡o cÃ¢u tráº£ lá»i)
   - LLM Ä‘á»c táº¥t cáº£ káº¿t quáº£ tÃ¬m Ä‘Æ°á»£c
   - Tá»•ng há»£p thÃ´ng tin tá»« cáº£ DB ná»™i bá»™ vÃ  web
   - Táº¡o cÃ¢u tráº£ lá»i cÃ³ cáº¥u trÃºc:
     - CÃ¡c Ä‘iá»u luáº­t liÃªn quan
     - PhÃ¢n tÃ­ch chi tiáº¿t
     - LÆ°u Ã½ (náº¿u cÃ³)

6. **Return Response**
   ```
   Agentic RAG â†’ Python API â†’ Go API â†’ React Frontend
   ```

### VÃ­ Dá»¥ Cá»¥ Thá»ƒ

**Input**:
```json
{
  "question": "Thá»i gian thá»­ viá»‡c tá»‘i Ä‘a bao nhiÃªu ngÃ y?"
}
```

**Processing**:
1. Decide: Search trong DB
2. Search: TÃ¬m tháº¥y Äiá»u 25 Bá»™ luáº­t Lao Ä‘á»™ng
3. Decide: Äá»§ thÃ´ng tin â†’ Generate answer
4. Generate: Táº¡o cÃ¢u tráº£ lá»i cÃ³ cáº¥u trÃºc

**Output**:
```json
{
  "answer": "1. CÃ¡c Ä‘iá»u luáº­t liÃªn quan:\n   - Äiá»u 25, Khoáº£n 2...\n\n2. PhÃ¢n tÃ­ch:\n   - 60 ngÃ y cho trÃ¬nh Ä‘á»™ cao Ä‘áº³ng+\n   - 30 ngÃ y cho trÃ¬nh Ä‘á»™ trung cáº¥p...",
  "iterations": 2,
  "search_results": [...],
  "web_results": [...]
}
```

---

## ğŸ“¦ CÃ i Äáº·t

### Prerequisites

1. **Go 1.21+**
   ```bash
   go version
   ```

2. **Python 3.8+**
   ```bash
   python --version
   ```

3. **Qdrant** (Vector Database)
   ```bash
   docker run -p 6333:6333 qdrant/qdrant
   ```

4. **Ollama** (LLM)
   ```bash
   # Install Ollama
   curl -fsSL https://ollama.com/install.sh | sh
   
   # Pull model
   ollama pull qwen2.5:7b
   
   # Start server
   ollama serve
   ```

5. **SearXNG** (Search Engine)
   ```bash
   # Included in docker-compose.yml
   docker-compose up -d searxng
   ```

### Installation Steps

1. **Clone Repository**
   ```bash
   git clone <repository-url>
   cd Legal-RAG
   ```

2. **Setup Python AI Engine**
   ```bash
   cd ai-engine
   
   # Install dependencies
   pip install -r requirements.txt
   
   # Configure environment
   cp .env.example .env
   # Edit .env with your settings
   
   # Ingest data (first time only)
   python run_embedding.py
   ```

3. **Setup Go Backend**
   ```bash
   cd ../backend-api
   
   # Install dependencies
   go mod download
   
   # Configure environment (optional)
   cp .env.example .env
   ```

4. **Setup React Frontend**
   ```bash
   cd ../frontend
   
   # Install dependencies
   npm install
   ```

---

## ğŸš€ Sá»­ Dá»¥ng

### Starting Services

**Terminal 1 - Qdrant** (if not using Docker):
```bash
docker run -p 6333:6333 qdrant/qdrant
```

**Terminal 2 - SearXNG**:
```bash
docker-compose up -d searxng
# Access web UI: http://localhost:8888
```

**Terminal 3 - Ollama**:
```bash
ollama serve
```

**Terminal 4 - Python AI Engine**:
```bash
cd ai-engine
python api_server.py
# Server running on http://localhost:8000
```

**Terminal 5 - Go Backend**:
```bash
cd backend-api
go run main.go
# Server running on http://localhost:8080
```

**Terminal 6 - React Frontend**:
```bash
cd frontend
npm run dev
# App running on http://localhost:5173
```

### Making Queries

#### Using curl

```bash
curl -X POST http://localhost:8080/api/legal-query \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Quy Ä‘á»‹nh vá» nghá»‰ phÃ©p nÄƒm lÃ  gÃ¬?"
  }'
```

#### Using Python

```python
import requests

response = requests.post(
    "http://localhost:8080/api/legal-query",
    json={"question": "Thá»i gian thá»­ viá»‡c tá»‘i Ä‘a bao nhiÃªu ngÃ y?"}
)

result = response.json()
print(result["answer"])
```

#### Using JavaScript

```javascript
fetch('http://localhost:8080/api/legal-query', {
  method: 'POST',
  headers: {'Content-Type': 'application/json'},
  body: JSON.stringify({
    question: 'LÆ°Æ¡ng tá»‘i thiá»ƒu vÃ¹ng 1 lÃ  bao nhiÃªu?'
  })
})
.then(res => res.json())
.then(data => console.log(data.answer));
```

### Advanced Options

```bash
curl -X POST http://localhost:8080/api/legal-query \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Quy Ä‘á»‹nh vá» báº£o hiá»ƒm xÃ£ há»™i",
    "max_iterations": 3,
    "top_k": 5,
    "enable_web_search": true
  }'
```

---

## ğŸ“ Cáº¥u TrÃºc Project

```
Legal-RAG/
â”œâ”€â”€ README.md                    # Documentation nÃ y
â”œâ”€â”€ docker-compose.yml           # Docker setup
â”œâ”€â”€ test_http_integration.sh     # Integration test script
â”‚
â”œâ”€â”€ frontend/                    # React Frontend (Vite + TS)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/                # API Client services
â”‚   â”‚   â”œâ”€â”€ components/         # UI Components
â”‚   â”‚   â”œâ”€â”€ hooks/              # Custom hooks (Chat, etc.)
â”‚   â”‚   â””â”€â”€ App.tsx             # Main Application
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ searxng/                     # SearXNG configuration
â”‚   â””â”€â”€ settings.yml            # Search engine settings
â”‚
â”œâ”€â”€ ai-engine/                   # Python AI Engine
â”‚   â”œâ”€â”€ api_server.py           # FastAPI HTTP server
â”‚   â”œâ”€â”€ run_embedding.py        # Data ingestion tool
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â”œâ”€â”€ .env.example            # Config template
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                   # Core modules
â”‚   â”‚   â”œâ”€â”€ agentic_rag.py     # Agentic RAG logic (LangGraph)
â”‚   â”‚   â”œâ”€â”€ search.py          # Search logic
â”‚   â”‚   â”œâ”€â”€ llm_generator.py   # LLM wrapper
â”‚   â”‚   â”œâ”€â”€ prompt_templates.py # Prompt templates
â”‚   â”‚   â””â”€â”€ web_search.py      # Web search (SearXNG)
â”‚   â”‚
â”‚   â”œâ”€â”€ embedding/              # Embedding modules
â”‚   â”‚   â”œâ”€â”€ embedder.py        # Vietnamese embedder
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â””â”€â”€ data/                   # Data directory
â”‚       â””â”€â”€ legal_documents/    # Source documents
â”‚
â””â”€â”€ backend-api/                # Go Backend API
    â”œâ”€â”€ main.go                 # Main server
    â”œâ”€â”€ go.mod                  # Go dependencies
    â”œâ”€â”€ .env.example            # Config template
    â””â”€â”€ README.md               # Backend documentation
```

### Key Files Explained

| File | MÃ´ Táº£ |
|------|-------|
| `ai-engine/api_server.py` | HTTP server expose Agentic RAG |
| `ai-engine/core/agentic_rag.py` | LangGraph workflow - "bá»™ nÃ£o" cá»§a há»‡ thá»‘ng |
| `ai-engine/core/search.py` | TÃ¬m kiáº¿m trong Qdrant vector DB |
| `ai-engine/core/web_search.py` | TÃ¬m kiáº¿m web qua SearXNG |
| `ai-engine/run_embedding.py` | Ingest documents vÃ o Qdrant |
| `backend-api/main.go` | Go API gateway |
| `searxng/settings.yml` | Cáº¥u hÃ¬nh SearXNG search engine |

---

## ğŸ“š API Documentation

### Endpoints

#### Go Backend API (Port 8080)

**POST /api/legal-query**
- Main endpoint cho client
- Request: `{"question": "string", ...}`
- Response: `{"answer": "string", "search_results": [...], "web_results": [...], ...}`

**GET /health**
- Health check
- Response: `{"status": "healthy", ...}`

#### Python AI Engine (Port 8000)

**POST /api/query**
- Internal endpoint (called by Go backend)
- Same request/response format

**GET /docs**
- Auto-generated OpenAPI documentation
- Visit: http://localhost:8000/docs

#### SearXNG (Port 8888)

**Web UI**
- Visit: http://localhost:8888
- Interactive search interface

**POST /search**
- JSON API endpoint
- Used internally by web_search.py

### Request Schema

```json
{
  "question": "string (required)",
  "max_iterations": 3,
  "top_k": 3,
  "enable_web_search": true
}
```

### Response Schema

```json
{
  "answer": "string",
  "search_results": [
    {
      "text": "string",
      "metadata": {
        "article_id": "string",
        "article_title": "string"
      },
      "score": 0.95,
      "source_type": "internal"
    }
  ],
  "web_results": [
    {
      "title": "string",
      "url": "string",
      "content": "string",
      "score": 0.9,
      "source_type": "web",
      "engine": "duckduckgo"
    }
  ],
  "iterations": 2,
  "query_used": "string"
}
```

---

## ğŸ”§ Configuration

### Environment Variables

#### Python AI Engine

```bash
# Qdrant Configuration
QDRANT_URL=http://localhost:6333
COLLECTION_NAME=legal_documents

# Ollama Configuration
OLLAMA_URL=http://127.0.0.1:11434
OLLAMA_MODEL=qwen2.5:7b

# SearXNG Configuration (for web search)
SEARXNG_URL=http://localhost:8888

# Embedding Model
EMBEDDING_MODEL=bkai-foundation-models/vietnamese-bi-encoder
```

#### Go Backend

```bash
GO_SERVER_PORT=8080
PYTHON_AI_ENGINE_URL=http://localhost:8000
REQUEST_TIMEOUT=60s
```

#### SearXNG

Edit `searxng/settings.yml`:

```yaml
server:
  secret_key: "your-secret-key"  # Change in production
  limiter: false  # Disable rate limiting for internal use

search:
  default_lang: "all"
  formats:
    - html
    - json
```

---

## ğŸ§ª Testing

### Integration Test

```bash
./test_http_integration.sh
```

This script tests:
1. Python AI Engine health
2. Go Backend health
3. SearXNG availability
4. Direct Python query
5. Full integration (Client â†’ Go â†’ Python)

### Manual Testing

```bash
# Test Python directly
curl http://localhost:8000/health

# Test Go backend
curl http://localhost:8080/health

# Test SearXNG
curl http://localhost:8888

# Test web search module
cd ai-engine && python core/web_search.py

# Test full flow
curl -X POST http://localhost:8080/api/legal-query \
  -H "Content-Type: application/json" \
  -d '{"question": "Test question"}'
```

---

## ğŸš€ Features

### âœ… Implemented

- âœ… Giao diá»‡n React Frontend hiá»‡n Ä‘áº¡i
- âœ… Agentic RAG vá»›i LangGraph
- âœ… Vector search vá»›i Qdrant
- âœ… Vietnamese LLM (Ollama qwen2.5:7b)
- âœ… Self-hosted web search (SearXNG)
- âœ… HTTP API (FastAPI + Gin)
- âœ… Docker deployment
- âœ… Multi-iteration search
- âœ… Query refinement
- âœ… Source citation

### ğŸ”„ Roadmap

- [x] Frontend UI
- [ ] User authentication
- [ ] Search history
- [ ] Document upload
- [ ] Multi-language support
- [ ] Advanced analytics

---

## ğŸ¤ Contributing

### Adding New Features

1. **New data sources**: Add to `ai-engine/data/`
2. **New prompts**: Edit `ai-engine/core/prompt_templates.py`
3. **New endpoints**: Add to `ai-engine/api_server.py` and `backend-api/main.go`
4. **Customize search**: Edit `searxng/settings.yml`

### Development Workflow

1. Make changes
2. Test locally
3. Run integration tests
4. Update documentation

---

## ğŸ“ License

MIT License

---

## ğŸ™ Acknowledgments

- **LangChain/LangGraph**: Agentic workflow framework
- **Qdrant**: Vector database
- **Ollama**: Local LLM inference
- **SearXNG**: Privacy-respecting metasearch engine
- **FastAPI**: Python web framework
- **Gin**: Go web framework

---

## ğŸ“ Support

For issues or questions:
1. Check documentation
2. Review API docs at http://localhost:8000/docs
3. Check SearXNG at http://localhost:8888
4. Check logs in terminal

---

**Built with â¤ï¸ for Vietnamese legal tech**
