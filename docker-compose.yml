version: '3.8'

services:
  # Qdrant Vector Database
  qdrant:
    image: qdrant/qdrant:latest
    container_name: legal-rag-qdrant
    ports:
      - "6333:6333"  # HTTP API
      - "6334:6334"  # gRPC API
    volumes:
      - qdrant_storage:/qdrant/storage
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334
    restart: unless-stopped
    networks:
      - legal-rag-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

  # Ollama LLM Service
  ollama:
    image: ollama/ollama:latest
    container_name: legal-rag-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_models:/root/.ollama
    restart: unless-stopped
    networks:
      - legal-rag-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    # Optional: GPU support (uncomment if you have NVIDIA GPU)
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

  # SearXNG Search Engine
  searxng:
    image: searxng/searxng:latest
    container_name: legal-rag-searxng
    ports:
      - "8888:8080"
    volumes:
      - ./searxng:/etc/searxng:rw
    environment:
      - SEARXNG_BASE_URL=http://localhost:8888/
    restart: unless-stopped
    networks:
      - legal-rag-network
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
    logging:
      driver: "json-file"
      options:
        max-size: "1m"
        max-file: "1"



  # Python AI Engine
  ai-engine:
    build:
      context: ./ai-engine
      dockerfile: Dockerfile
    container_name: legal-rag-ai-engine
    ports:
      - "8000:8000"
    volumes:
      - ./ai-engine/data:/app/data  # Mount data directory
    environment:
      - QDRANT_URL=http://qdrant:6333
      - COLLECTION_NAME=legal_documents
      - OLLAMA_URL=http://ollama:11434
      - OLLAMA_MODEL=qwen2.5:7b
      - SEARXNG_URL=http://searxng:8080
    depends_on:
      qdrant:
        condition: service_healthy
      ollama:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - legal-rag-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Go Backend API
  backend-api:
    build:
      context: ./backend-api
      dockerfile: Dockerfile
    container_name: legal-rag-backend
    ports:
      - "8080:8080"
    environment:
      - GO_SERVER_PORT=8080
      - PYTHON_AI_ENGINE_URL=http://ai-engine:8000
      - REQUEST_TIMEOUT=60s
    depends_on:
      ai-engine:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - legal-rag-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

volumes:
  qdrant_storage:
    driver: local
  ollama_models:
    driver: local

networks:
  legal-rag-network:
    driver: bridge
